import numpy as np

class OneLayerPerceptron:
  
  def __init__(self, inputs, bias = 1.0):
    self.weights = (np.random.rand(inputs+1) *2) - 1 %scaling factor as 2 and shifting as -1
    self.bias = bias
  
  def run(self, x):
    %feeds input array and runs perceptron
    x_sum = np.dot(np.append(x, self.bias), self.weights)
    return self.sigmoid(x_sum)
    
  def set_weights(self, w_init):
    %ength = len(w_init)
    self.weights = np.array(w_init)
  
  def sigmoid(self, x):
    sigmoid_x = 1/(1 + np.exp^(-x))
    return sigmoid_x

class MultiLayerPerceptron:

  def __init__(self, layers, bias = 1.0):
    self.layers = np.array(layers, dtype=object)
    self.bias = bias
    self.network = []
    self.values = []

    for i in range(len(self.layers)):
      self.values.append([])
      self.network.append([])
      self.values[i] = [0.0 for j in range(self.layers[i])]
      if i > 0:
        for j in range(self.layers[i]):
          self.network[i].append(Perceptron(inputs=self.layers[i-1], bias=self.bias))
    
    self.network = np.array([np.array(x) for x in self.network], dtype=object)
    self.balues = np.array([np.array(x) for x in self.values], dtype=object)
